{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 加载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir ./dataset\n",
    "# !wget https://bj.bcebos.com/ai-studio-online/9d140236f9ab4fc885ea57f6390a8f5ac102997cbb6549db9b5278e44aa2ce31?authorization=bce-auth-v1%2F5cfe9a5e1454405eb2a975c43eace6ec%2F2022-09-04T15%3A26%3A53Z%2F-1%2F%2F20eccb3d8f5781c7b2261eb18d830228ebf5e1f9e1567f6ed670d5d0539005b2&responseContentDisposition=attachment%3B%20filename%3Dfaces.zip -O ./dataset/faces.zip\n",
    "# !mv 9d140236f9ab4fc885ea57f6390a8f5ac102997cbb6549db9b5278e44aa2ce31?authorization=bce-auth-v1%2F5cfe9a5e1454405eb2a975c43eace6ec%2F2022-09-04T15:26:53Z%2F-1%2F%2F20eccb3d8f5781c7b2261eb18d830228ebf5e1f9e1567f6ed670d5d0539005b2.2 ./dataset/faces.zip\n",
    "# !unzip -qd ./dataset/faces ./dataset/faces.zip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data_dir, data_file, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.data_file = data_file\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_file)\n",
    "    \n",
    "    def __getitem__(self, index) -> torch.Tensor:\n",
    "        img = cv2.imread(self.data_dir + self.data_file[index])\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = img / 255.0\n",
    "        img = torch.from_numpy(img).float().permute(2, 0, 1)\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img\n",
    "    \n",
    "data_dir = './dataset/faces/'\n",
    "data_file = os.listdir(data_dir)\n",
    "data_file.sort() # 不同系统下，文件夹中的文件顺序不同，所以排个序以为后续复现训练结果做准备\n",
    "dataset = MyDataset(data_dir, data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "# 查看1张图片\n",
    "plt.figure(figsize=(1, 1))\n",
    "plt.imshow(dataloader.dataset[0].permute(1, 2, 0))\n",
    "\n",
    "# 查看数据集的shape\n",
    "for i in dataloader:\n",
    "    print(i.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 扩散过程（Diffusion Process）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算超参数\n",
    "T = 250 # 迭代次数, 也就是时间步数\n",
    "beta_t = torch.linspace(0, 1, T)\n",
    "alpha_t = 1 - beta_t\n",
    "sqrt_alpha_t = torch.sqrt(alpha_t)\n",
    "alpha_t_bar = torch.cumprod(alpha_t, dim=0)\n",
    "sqrt_alpha_t_bar = torch.sqrt(alpha_t_bar)\n",
    "sqrt_one_minus_alpha_t_bar = torch.sqrt(1 - alpha_t_bar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算扩散过程q中任意时刻的q(x_t)\n",
    "def q_x(x0, t):\n",
    "    \"\"\"\n",
    "    x0: 初始图片\n",
    "    t: 时间步\n",
    "    \"\"\"\n",
    "    x0 = x0\n",
    "    t = t\n",
    "    x_t = sqrt_alpha_t_bar[t] * x0 + sqrt_one_minus_alpha_t_bar[t] * torch.randn_like(x0)\n",
    "    return x_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 演示200步扩散过程\n",
    "plt.figure(figsize=(20, 20))\n",
    "for i in range(0, 200, 10):\n",
    "    plt.subplot(4, 5, i // 10 + 1)\n",
    "    plt.title(f't={i}')\n",
    "    plt.imshow(q_x(dataloader.dataset[0], i).permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 逆扩散过程（Reverse Diffusion Process）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 UNet网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 搭建网络用于预测噪声\n",
    "# 参考链接：https://zhuanlan.zhihu.com/p/609396803 (搭建UNet)\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, T, embed_dim):\n",
    "        \"\"\"\n",
    "        in_channels: 输入通道数\n",
    "        out_channels: 输出通道数\n",
    "        T: 总时间步数\n",
    "        \"\"\"\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        # 时间步数的嵌入空间\n",
    "        self.time_embedding = nn.Embedding(T, embed_dim)\n",
    "\n",
    "        # 编码器（下采样路径）\n",
    "        self.down_conv1 = nn.Sequential(\n",
    "            self.conv_block(in_channels + 1, 64), # 1是嵌入的时间步信息的维度\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "        )\n",
    "        self.down_conv2 = nn.Sequential(\n",
    "            self.conv_block(64, 128),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "        )\n",
    "        self.down_conv3 = nn.Sequential(\n",
    "            self.conv_block(128, 256),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "        )\n",
    "        self.down_conv4 = nn.Sequential(\n",
    "            self.conv_block(256, 512),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "        )\n",
    "        self.down_conv5 = nn.Sequential(\n",
    "            self.conv_block(512, 1024),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "        )\n",
    "\n",
    "        # 解码器（上采样路径）\n",
    "        self.up_sample1 = self.conv_transpose_block(1024, 512)\n",
    "        self.up_conv1 = self.conv_block(1024, 512)\n",
    "        self.up_sample2 = self.conv_transpose_block(512, 256)\n",
    "        self.up_conv2 = self.conv_block(512, 256)\n",
    "        self.up_sample3 = self.conv_transpose_block(256, 128)\n",
    "        self.up_conv3 = self.conv_block(256, 128)\n",
    "        self.up_sample4 = self.conv_transpose_block(128, 64)\n",
    "        self.up_conv4 = self.conv_block(128, 64)\n",
    "\n",
    "        self.restore_shape_layer = nn.ConvTranspose2d(64, 64, 3, stride=2, padding=1, output_padding=1)\n",
    "        \n",
    "        self.output_layer = nn.Conv2d(64, out_channels, kernel_size=1)\n",
    "    \n",
    "\n",
    "    def forward(self, x, t):\n",
    "        # 新增一个通道嵌入时间信息\n",
    "        batch_size = t.shape[0]\n",
    "        t_embed = self.time_embedding(t).view(batch_size, 1, 256,256)\n",
    "        x = torch.cat([x, t_embed], dim=1)\n",
    "\n",
    "        # 下采样\n",
    "        x1 = self.down_conv1(x)\n",
    "        x2 = self.down_conv2(x1)\n",
    "        x3 = self.down_conv3(x2)\n",
    "        x4 = self.down_conv4(x3)\n",
    "        x = self.down_conv5(x4)\n",
    "        \"\"\"\n",
    "        x1: torch.Size([1, 64, 128, 128]),\n",
    "        x2: torch.Size([1, 128, 64, 64]),\n",
    "        x3: torch.Size([1, 256, 32, 32]),\n",
    "        x4: torch.Size([1, 512, 16, 16]),\n",
    "        x: torch.Size([1, 1024, 8, 8])\n",
    "        \"\"\"\n",
    "\n",
    "        # 上采样\n",
    "        x = self.up_sample1(x)\n",
    "        x = torch.cat([x, x4], dim=1)\n",
    "        x = self.up_conv1(x)\n",
    "        x = self.up_sample2(x)\n",
    "        x = torch.cat([x, x3], dim=1)\n",
    "        x = self.up_conv2(x)\n",
    "        x = self.up_sample3(x)\n",
    "        x = torch.cat([x, x2], dim=1)\n",
    "        x = self.up_conv3(x)\n",
    "        x = self.up_sample4(x)\n",
    "        x = torch.cat([x, x1], dim=1)\n",
    "        x = self.up_conv4(x)\n",
    "        x = self.restore_shape_layer(x)\n",
    "        x = self.output_layer(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def conv_block(self, in_channels, out_channels):\n",
    "        block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        return block\n",
    "    \n",
    "    def conv_transpose_block(self, in_channels, out_channels):\n",
    "        block = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels, out_channels, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        return block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = torch.hub.load('mateuszbuda/brain-segmentation-pytorch', 'unet',\n",
    "#     in_channels=3, out_channels=3, init_features=32, pretrained=False)\n",
    "# 测试网络\n",
    "model = UNet(3, 3, T, 256*256)\n",
    "test_img = dataset[0].unsqueeze(0)\n",
    "\n",
    "t = torch.tensor(100)\n",
    "t = t.unsqueeze(-1)\n",
    "\n",
    "test_result = model(test_img, t)\n",
    "print(test_img.shape)\n",
    "print(test_result.shape)\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(test_img.squeeze(0).permute((1, 2, 0)))\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(test_result.squeeze(0).permute((1, 2, 0)).detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Loss函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(model, x_0, sqrt_alpha_t_bar, sqrt_one_minus_alpha_t_bar, T, device=device):\n",
    "    \"\"\"\n",
    "    model: 预测噪声的网络\n",
    "    x_0: 初始图片\n",
    "    sqrt_alpha_t_bar: sqrt(alpha_t_bar)\n",
    "    sqrt_one_minus_alpha_t_bar: sqrt(1 - alpha_t_bar)\n",
    "    T: 总时间步数\n",
    "\n",
    "    对任意时刻t进行采样，计算损失\n",
    "    \"\"\"\n",
    "    batch_size = x_0.shape[0]\n",
    "    # 采样t，采样一半，另一半为T-1-t，防止t重复过多，提高训练效率\n",
    "    t = torch.randint(0, T, size=(batch_size//2,))\n",
    "    try:\n",
    "        t = torch.cat([t, T-1-t], dim=0)\n",
    "    except:\n",
    "        t = t\n",
    "    t = t.unsqueeze(-1)\n",
    "\n",
    "    x_0_coeff = sqrt_alpha_t_bar[t].unsqueeze(-1).unsqueeze(-1) # x0的系数\n",
    "    epsilon_coeff = sqrt_one_minus_alpha_t_bar[t].unsqueeze(-1).unsqueeze(-1) # 噪声的系数\n",
    "    epsilon = torch.randn_like(x_0)\n",
    "    x = x_0_coeff * x_0 + epsilon_coeff * epsilon # 采样得到的x\n",
    "    x = x.to(device)\n",
    "    t = t.to(device)\n",
    "    epsilon_predict = model(x, t)\n",
    "    return F.mse_loss(epsilon, epsilon_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 逆扩散采样\n",
    "\n",
    "逆扩散过程p中，我们要训练的是 $p_{\\theta}(x_{t-1} | x_t)$\n",
    "\n",
    "在扩散过程q中，t-1时刻噪声的后验概率为 $q(x_{t-1} | x_t, x_0)\\ \\~{} \\ N(\\tilde \\mu_t(x_t, x_0),\\ \\tilde \\beta_t \\mathbf{I})$\n",
    "\n",
    "其中 $\\tilde \\mu_t(x_t, x_0) = \\cfrac{1}{\\sqrt{\\alpha_t} } (x_t - \\cfrac{\\beta_t}{\\sqrt{1-\\alpha_t}} \\cdot z_t),\\ where\\ z_t\\ \\~{} \\ N(0,\\ \\mathbf{I})$, $\\tilde \\beta_t $为常数\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_sample(model, x, t, beta_t, sqrt_alpha_t, sqrt_one_minus_alpha_t_bar):\n",
    "    \"\"\"\n",
    "    model: 预测噪声的网络\n",
    "    x: 初始图片\n",
    "    t: 时间步\n",
    "    beta_t: beta_t\n",
    "    sqrt_alpha_t_bar: sqrt(alpha_t_bar)\n",
    "    sqrt_one_minus_alpha_t_bar: sqrt(1 - alpha_t_bar)\n",
    "\n",
    "    从 x[t] 采样得到 x[t-1]\n",
    "    \"\"\"\n",
    "    t = torch.tensor([t])\n",
    "    epsilon_theta = model(x, t)\n",
    "\n",
    "    mean = (1 / sqrt_alpha_t[t]) * (x - beta_t[t] / sqrt_one_minus_alpha_t_bar[t] * epsilon_theta)\n",
    "    var = beta_t[t].sqrt()\n",
    "\n",
    "    sample = mean + var * torch.randn_like(x)\n",
    "\n",
    "    return (sample)\n",
    "    \n",
    "    \n",
    "\n",
    "def p_sample_loop(model, shape, T, beta_t, sqrt_alpha_t, sqrt_one_minus_alpha_t_bar):\n",
    "    \"\"\"\n",
    "    从 x[T] 恢复 x[T-1], x[T-2], ..., x[0]\n",
    "    \"\"\"\n",
    "    cur_x = torch.randn(shape)\n",
    "    x_seq = [cur_x]\n",
    "    for t in reversed(range(T)):\n",
    "        cur_x = p_sample(model, cur_x, t, beta_t, sqrt_alpha_t, sqrt_one_minus_alpha_t_bar)\n",
    "        x_seq.append(cur_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epoch = 100\n",
    "model = UNet(3, 3, T, 256*256)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train(model, optimizer, n_epoch, dataloader, T, beta_t, sqrt_alpha_t, sqrt_one_minus_alpha_t_bar):\n",
    "    model.train()\n",
    "    for epoch in range(n_epoch):\n",
    "        with tqdm(dataloader, total=len(dataloader)) as t:\n",
    "            for batch in t:\n",
    "                optimizer.zero_grad()\n",
    "                loss_value = loss(model, batch, sqrt_alpha_t_bar, sqrt_one_minus_alpha_t_bar, T)\n",
    "                loss_value.backward()\n",
    "                optimizer.step()\n",
    "                t.set_description(f'epoch:{epoch}, loss:{loss.item():.4f}')\n",
    "\n",
    "        if epoch % 20 == 0:\n",
    "            torch.save(model.state_dict(), f'./model/model_{epoch}.pth')\n",
    "            x_seq = p_sample_loop(model, (1,3,256,256), T, beta_t, sqrt_alpha_t, sqrt_one_minus_alpha_t_bar)\n",
    "            plt.figure(figsize=(20, 20))\n",
    "            for i in range(0, 250, 10):\n",
    "                plt.subplot(5, 5, i // 10 + 1)\n",
    "                plt.title(f't={i}')\n",
    "                plt.imshow(x_seq[i].squeeze(0).permute(1, 2, 0).detach().numpy())\n",
    "\n",
    "train(model, optimizer, n_epoch, dataloader, T, beta_t, sqrt_alpha_t, sqrt_one_minus_alpha_t_bar)\n",
    "\n",
    "# 保存模型\n",
    "import os\n",
    "if not os.path.exists('./model'):\n",
    "    os.mkdir('./model')\n",
    "torch.save(model.state_dict(), './model/model.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
