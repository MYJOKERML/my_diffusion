{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: tensor([ 0.0039,  0.0116,  0.0173,  0.0107, -0.0036, -0.0065, -0.0083, -0.0042,\n",
      "         0.0016, -0.0098]), var: tensor([1.0112, 1.0186, 1.0239, 0.9929, 1.0001, 0.9946, 0.9845, 0.9929, 1.0022,\n",
      "        0.9675])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "T = 1000\n",
    "BATCH_SIZE = 16\n",
    "# 探索torch的normal分布\n",
    "e = torch.normal(mean=torch.arange(1., 11.), std=torch.arange(1, 0, -0.1))\n",
    "e = torch.randn((10000, 10))\n",
    "mean = torch.mean(e, dim=0)\n",
    "var = torch.var(e, dim=0)\n",
    "print(f'mean: {mean}, var: {var}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1, 16])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 测试嵌入时间步信息\n",
    "pos_embedding = nn.Embedding(T, BATCH_SIZE) \n",
    "t = torch.randint(0, T, (10, 1))\n",
    "pos_embedding(t).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3],\n",
      "        [0]])\n",
      "tensor([[3],\n",
      "        [0]])\n",
      "torch.Size([1, 3])\n",
      "torch.Size([1, 3, 1, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 16, 16])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 切片和广播\n",
    "a = torch.randint(0, 10, (2, 3))\n",
    "print(a[:,1:2])\n",
    "print(a[...,1:2])\n",
    "\n",
    "T = 150\n",
    "t = nn.Linear(T, 3)\n",
    "time_embed = t(torch.randn(1, T))\n",
    "print(time_embed.shape)\n",
    "time_embed = time_embed[(..., ) + (None, ) * 2]\n",
    "print(time_embed.shape)\n",
    "(..., ) + (None, )*2\n",
    "\n",
    "x = torch.zeros(1, 3, 16, 16)\n",
    "x = x + time_embed\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([150, 128])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = nn.Embedding(T, 128)\n",
    "time_embed = t(torch.arange(T))\n",
    "time_embed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SinusoidalPositionalEmbedding(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "    \n",
    "    def forward(self, t: torch.Tensor):\n",
    "        half_dim = self.dim // 2\n",
    "        emb = np.log(10000) / (half_dim - 1)\n",
    "        emb = torch.exp(torch.arange(half_dim, dtype=torch.float32) * -emb)\n",
    "        emb = t.unsqueeze(-1) * emb.unsqueeze(0)\n",
    "        emb = torch.cat([torch.sin(emb), torch.cos(emb)], dim=-1)\n",
    "        return emb\n",
    "\n",
    "test = SinusoidalPositionalEmbedding(128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6, 512, 512])\n"
     ]
    }
   ],
   "source": [
    "# 探索反卷积的用法\n",
    "\n",
    "a = torch.randn(1, 3, 256, 256)\n",
    "a_conv_transpose = nn.ConvTranspose2d(3, 6, 3, stride=2, padding=1, output_padding=1)\n",
    "print(a_conv_transpose(a).shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
